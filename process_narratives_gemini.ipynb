{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Process Life Narratives with Gemini Pro 2.5\n",
        "\n",
        "This notebook processes text files containing life histories and scores them on:\n",
        "- **A**: Enjoyment of consumption and leisure\n",
        "- **B**: Making a difference and contributing\n",
        "\n",
        "Results are saved incrementally to CSV with resume capability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q google-generativeai pandas seaborn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CONFIGURATION - ADJUST PARAMETERS HERE\n",
        "# ============================================================\n",
        "\n",
        "SAMPLE_SIZE = None  # Set to None to process all files, or set a number (e.g., 10, 50, 100)\n",
        "\n",
        "# Directory containing the text files\n",
        "STORIES_DIR = '/content/drive/MyDrive/all-narratives_cleanedtxtfiles'\n",
        "\n",
        "# Output CSV file (starts with . to appear at top of directory)\n",
        "OUTPUT_CSV = '/content/drive/MyDrive/all-narratives_cleanedtxtfiles/.results_narrative_scores.csv'\n",
        "\n",
        "# Error log file\n",
        "ERROR_LOG = '/content/drive/MyDrive/all-narratives_cleanedtxtfiles/.error_log.txt'\n",
        "\n",
        "# Rate limiting (requests per minute) - set to None for no limit\n",
        "RATE_LIMIT = None\n",
        "\n",
        "# Max concurrent requests\n",
        "MAX_CONCURRENT = 10\n",
        "\n",
        "# Gemini model to use\n",
        "MODEL_NAME = 'gemini-2.0-flash-exp'  # or 'gemini-pro' depending on availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import asyncio\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Optional, Dict, List\n",
        "import json\n",
        "\n",
        "# Configure Gemini API\n",
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the prompt template\n",
        "PROMPT_TEMPLATE = \"\"\"You are an expert historian. Read this life history. Consider two possible sources of satisfaction and meaning:\n",
        "\n",
        "a. Enjoying consumption and leisure -- making the most of what life has to offer?\n",
        "b. How much of a difference do you make, how much can you create and contribute (both materially and spiritually)?\n",
        "\n",
        "You have 10 points to award, overall, max. If the person derives no satisfaction from a, give 0 points. If they get the same satisfaction from a+b, give 5 points each. No need to use up all points.\n",
        "\n",
        "Explain your reasoning, by category (overall points, points for a, for b).\n",
        "\n",
        "IMPORTANT: Format your response exactly as follows:\n",
        "POINTS-A: [number]\n",
        "POINTS-B: [number]\n",
        "REASONING-A: [your explanation for category A]\n",
        "REASONING-B: [your explanation for category B]\n",
        "\n",
        "Life history:\n",
        "{story_text}\"\"\"\n",
        "\n",
        "\n",
        "def parse_gemini_response(response_text: str) -> Dict[str, any]:\n",
        "    \"\"\"Parse the Gemini response to extract points and reasoning.\"\"\"\n",
        "    result = {\n",
        "        'points_a': None,\n",
        "        'points_b': None,\n",
        "        'reasoning_a': '',\n",
        "        'reasoning_b': ''\n",
        "    }\n",
        "    \n",
        "    # Extract points for A\n",
        "    match_a = re.search(r'POINTS-A:\\s*([0-9.]+)', response_text, re.IGNORECASE)\n",
        "    if match_a:\n",
        "        result['points_a'] = float(match_a.group(1))\n",
        "    \n",
        "    # Extract points for B\n",
        "    match_b = re.search(r'POINTS-B:\\s*([0-9.]+)', response_text, re.IGNORECASE)\n",
        "    if match_b:\n",
        "        result['points_b'] = float(match_b.group(1))\n",
        "    \n",
        "    # Extract reasoning for A\n",
        "    match_reasoning_a = re.search(r'REASONING-A:\\s*(.+?)(?=REASONING-B:|$)', response_text, re.IGNORECASE | re.DOTALL)\n",
        "    if match_reasoning_a:\n",
        "        result['reasoning_a'] = match_reasoning_a.group(1).strip()\n",
        "    \n",
        "    # Extract reasoning for B\n",
        "    match_reasoning_b = re.search(r'REASONING-B:\\s*(.+?)$', response_text, re.IGNORECASE | re.DOTALL)\n",
        "    if match_reasoning_b:\n",
        "        result['reasoning_b'] = match_reasoning_b.group(1).strip()\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "def log_error(filename: str, error: str):\n",
        "    \"\"\"Log errors to error log file.\"\"\"\n",
        "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    with open(ERROR_LOG, 'a', encoding='utf-8') as f:\n",
        "        f.write(f\"{timestamp} | {filename} | {error}\\n\")\n",
        "\n",
        "\n",
        "def get_processed_files() -> set:\n",
        "    \"\"\"Get list of already processed files from existing CSV.\"\"\"\n",
        "    if os.path.exists(OUTPUT_CSV):\n",
        "        try:\n",
        "            df = pd.read_csv(OUTPUT_CSV)\n",
        "            return set(df['filename'].tolist())\n",
        "        except Exception as e:\n",
        "            print(f\"Could not read existing CSV: {e}\")\n",
        "            return set()\n",
        "    return set()\n",
        "\n",
        "\n",
        "def save_result(filename: str, points_a: float, points_b: float, reasoning_a: str, reasoning_b: str):\n",
        "    \"\"\"Save a single result to CSV (append mode).\"\"\"\n",
        "    result_df = pd.DataFrame([{\n",
        "        'filename': filename,\n",
        "        'points-a': points_a,\n",
        "        'points-b': points_b,\n",
        "        'reasoning-a': reasoning_a,\n",
        "        'reasoning-b': reasoning_b\n",
        "    }])\n",
        "    \n",
        "    # Check if file exists to determine if we need to write header\n",
        "    file_exists = os.path.exists(OUTPUT_CSV)\n",
        "    result_df.to_csv(OUTPUT_CSV, mode='a', header=not file_exists, index=False)\n",
        "\n",
        "\n",
        "async def process_file(model, filepath: Path, semaphore: asyncio.Semaphore) -> bool:\n",
        "    \"\"\"Process a single text file with Gemini.\"\"\"\n",
        "    async with semaphore:\n",
        "        filename = filepath.name\n",
        "        \n",
        "        try:\n",
        "            # Read the story\n",
        "            with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                story_text = f.read()\n",
        "            \n",
        "            # Create prompt\n",
        "            prompt = PROMPT_TEMPLATE.format(story_text=story_text)\n",
        "            \n",
        "            # Call Gemini API (synchronous call in async context)\n",
        "            loop = asyncio.get_event_loop()\n",
        "            response = await loop.run_in_executor(\n",
        "                None,\n",
        "                lambda: model.generate_content(prompt)\n",
        "            )\n",
        "            \n",
        "            # Parse response\n",
        "            response_text = response.text\n",
        "            parsed = parse_gemini_response(response_text)\n",
        "            \n",
        "            # Check if parsing was successful\n",
        "            if parsed['points_a'] is None or parsed['points_b'] is None:\n",
        "                raise ValueError(f\"Could not extract points from response: {response_text[:200]}\")\n",
        "            \n",
        "            # Save result immediately\n",
        "            save_result(\n",
        "                filename=filename,\n",
        "                points_a=parsed['points_a'],\n",
        "                points_b=parsed['points_b'],\n",
        "                reasoning_a=parsed['reasoning_a'],\n",
        "                reasoning_b=parsed['reasoning_b']\n",
        "            )\n",
        "            \n",
        "            print(f\"✓ Processed: {filename} (A={parsed['points_a']}, B={parsed['points_b']})\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            error_msg = str(e)\n",
        "            log_error(filename, error_msg)\n",
        "            print(f\"✗ Error processing {filename}: {error_msg}\")\n",
        "            return False\n",
        "\n",
        "\n",
        "async def process_all_files():\n",
        "    \"\"\"Process all text files in the directory.\"\"\"\n",
        "    # Initialize model\n",
        "    model = genai.GenerativeModel(MODEL_NAME)\n",
        "    \n",
        "    # Get list of text files\n",
        "    stories_path = Path(STORIES_DIR)\n",
        "    all_files = sorted(list(stories_path.glob('*.txt')))\n",
        "    \n",
        "    # Apply sample size if specified\n",
        "    if SAMPLE_SIZE is not None:\n",
        "        all_files = all_files[:SAMPLE_SIZE]\n",
        "        print(f\"Processing {SAMPLE_SIZE} files (sample)\")\n",
        "    else:\n",
        "        print(f\"Processing all {len(all_files)} files\")\n",
        "    \n",
        "    # Get already processed files\n",
        "    processed_files = get_processed_files()\n",
        "    files_to_process = [f for f in all_files if f.name not in processed_files]\n",
        "    \n",
        "    if len(processed_files) > 0:\n",
        "        print(f\"Resuming: {len(processed_files)} already processed, {len(files_to_process)} remaining\")\n",
        "    \n",
        "    if len(files_to_process) == 0:\n",
        "        print(\"All files already processed!\")\n",
        "        return\n",
        "    \n",
        "    # Create semaphore for rate limiting\n",
        "    semaphore = asyncio.Semaphore(MAX_CONCURRENT)\n",
        "    \n",
        "    # Process files\n",
        "    start_time = time.time()\n",
        "    tasks = [process_file(model, filepath, semaphore) for filepath in files_to_process]\n",
        "    results = await asyncio.gather(*tasks)\n",
        "    \n",
        "    # Summary\n",
        "    elapsed = time.time() - start_time\n",
        "    success_count = sum(results)\n",
        "    print(f\"\\n\" + \"=\"*60)\n",
        "    print(f\"Processing complete!\")\n",
        "    print(f\"Total files: {len(files_to_process)}\")\n",
        "    print(f\"Successful: {success_count}\")\n",
        "    print(f\"Failed: {len(files_to_process) - success_count}\")\n",
        "    print(f\"Time elapsed: {elapsed:.2f} seconds\")\n",
        "    print(f\"Results saved to: {OUTPUT_CSV}\")\n",
        "    if len(files_to_process) - success_count > 0:\n",
        "        print(f\"Errors logged to: {ERROR_LOG}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "print(\"Functions defined. Ready to process files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the processing\n",
        "await process_all_files()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizations\n",
        "\n",
        "Create distributions and scatterplots for the scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load results\n",
        "df = pd.read_csv(OUTPUT_CSV)\n",
        "\n",
        "print(f\"Loaded {len(df)} results\")\n",
        "print(f\"\\nSummary statistics:\")\n",
        "print(df[['points-a', 'points-b']].describe())\n",
        "\n",
        "# Show first few rows\n",
        "print(f\"\\nFirst 5 results:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set seaborn style\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Create figure with subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle('Life Narrative Satisfaction Scores', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Distribution of Points-A (Consumption/Leisure)\n",
        "sns.histplot(df['points-a'], bins=20, kde=True, ax=axes[0, 0], color='skyblue')\n",
        "axes[0, 0].set_title('Distribution of Points-A\\n(Consumption & Leisure)', fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Points-A')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].axvline(df['points-a'].mean(), color='red', linestyle='--', label=f\"Mean: {df['points-a'].mean():.2f}\")\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# 2. Distribution of Points-B (Contribution/Difference)\n",
        "sns.histplot(df['points-b'], bins=20, kde=True, ax=axes[0, 1], color='lightcoral')\n",
        "axes[0, 1].set_title('Distribution of Points-B\\n(Contribution & Difference)', fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Points-B')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].axvline(df['points-b'].mean(), color='red', linestyle='--', label=f\"Mean: {df['points-b'].mean():.2f}\")\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# 3. Scatterplot: Points-A vs Points-B\n",
        "sns.scatterplot(data=df, x='points-a', y='points-b', ax=axes[1, 0], alpha=0.6, s=50)\n",
        "axes[1, 0].set_title('Points-A vs Points-B', fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Points-A (Consumption & Leisure)')\n",
        "axes[1, 0].set_ylabel('Points-B (Contribution & Difference)')\n",
        "axes[1, 0].plot([0, 10], [0, 10], 'r--', alpha=0.3, label='Equal points line')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# 4. Total points distribution\n",
        "df['total_points'] = df['points-a'] + df['points-b']\n",
        "sns.histplot(df['total_points'], bins=20, kde=True, ax=axes[1, 1], color='lightgreen')\n",
        "axes[1, 1].set_title('Distribution of Total Points\\n(A + B)', fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Total Points')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].axvline(df['total_points'].mean(), color='red', linestyle='--', label=f\"Mean: {df['total_points'].mean():.2f}\")\n",
        "axes[1, 1].axvline(10, color='orange', linestyle='--', alpha=0.5, label='Max (10)')\n",
        "axes[1, 1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nCorrelation between Points-A and Points-B: {df['points-a'].corr(df['points-b']):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Additional analysis: Show some examples\n",
        "print(\"Examples of high Points-A (Consumption/Leisure):\")\n",
        "print(df.nlargest(3, 'points-a')[['filename', 'points-a', 'points-b', 'reasoning-a']])\n",
        "\n",
        "print(\"\\nExamples of high Points-B (Contribution/Difference):\")\n",
        "print(df.nlargest(3, 'points-b')[['filename', 'points-a', 'points-b', 'reasoning-b']])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
